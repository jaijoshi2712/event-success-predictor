{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5136efee-3059-4670-9bf1-bbc4aa44c724",
   "metadata": {},
   "source": [
    "#### This notebook contains all the exploration steps run on raw data before it is ready to ingest into a database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b83a30ce-5bb5-4f05-8c7b-c607d6430151",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import pyspark.sql.functions as F\n",
    "import pyspark.sql.types as T\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e13883f-369c-419b-b3bb-bf44a75198f8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/12/03 23:13:06 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "23/12/03 23:13:07 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "/Users/priyangshupal/anaconda3/lib/python3.11/site-packages/pyspark/sql/context.py:157: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "conf = pyspark.SparkConf()\n",
    "# conf.set('spark.ui.proxyBase', '/user/' + os.environ['JUPYTERHUB_USER'] + '/proxy/4041')\n",
    "conf.set('spark.driver.memory','3g')\n",
    "conf.set('spark.ui.showConsoleProgress', False)\n",
    "sc = pyspark.SparkContext(conf=conf)\n",
    "spark = pyspark.SQLContext.getOrCreate(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75704e5c-b246-4e16-b445-5428d9e0a3d5",
   "metadata": {},
   "source": [
    "### Twitter Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa0fd85c-5a12-4b65-a493-044976cd57be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "twitter_data = spark.read.csv('../data/Twitter_Data.csv', multiLine=True, header=True).select(['clean_text', 'category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50863457-e3ad-4d75-9698-2e8accf47575",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "107760"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5072557-a6bc-421e-81a6-902c1129f4ce",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- clean_text: string (nullable = true)\n",
      " |-- category: string (nullable = true)\n",
      "\n",
      "+--------------------+--------+\n",
      "|          clean_text|category|\n",
      "+--------------------+--------+\n",
      "|when modi promise...|    -1.0|\n",
      "|what did just say...|     1.0|\n",
      "|asking his suppor...|     1.0|\n",
      "|answer who among ...|     1.0|\n",
      "|with upcoming ele...|     1.0|\n",
      "|gandhi was gay do...|     1.0|\n",
      "|things like demon...|     1.0|\n",
      "|hope tuthukudi pe...|     1.0|\n",
      "|calm waters where...|     1.0|\n",
      "|vote such party a...|    -1.0|\n",
      "+--------------------+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "twitter_data.printSchema()\n",
    "twitter_data.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "958926c9-4029-443b-bb46-a673d2715dc6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "twitter_data = twitter_data.withColumnRenamed('clean_text', 'text')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7813d20f-c977-475a-9908-0022d15e4fcc",
   "metadata": {},
   "source": [
    "Checking for NULL rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4032c40c-aae8-43f4-893f-e41b6a3009fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_data.filter((F.col('category').isNull() | F.col('text').isNull())).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3afa0054-e4c7-4ee5-a1bc-7e8a339af8be",
   "metadata": {},
   "source": [
    "Removing NULL rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30304a2e-d61a-47c6-9503-08596f0c4236",
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_data = twitter_data.filter(~(F.col('category').isNull() | F.col('text').isNull()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0918b412-5bdb-42d4-9f1c-52f3a524614d",
   "metadata": {},
   "source": [
    "This DataFrame has 2 categories:\n",
    "\n",
    "-1 $\\Rightarrow$ Negative sentiment <br>\n",
    "1 $\\Rightarrow$ Positive sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b31def17-b7a1-4d40-852a-8800a92b3966",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|category|\n",
      "+--------+\n",
      "|     1.0|\n",
      "|    -1.0|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "twitter_data.select('category').distinct().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c705fc-5109-42f3-b312-369be83b0580",
   "metadata": {},
   "source": [
    "### Sentiment140 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec395a7a-d575-4ddc-ac6b-18e43a82aca9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sentiment140Schema = T.StructType([\n",
    "    T.StructField(\"target\", T.StringType(), True),        \n",
    "    T.StructField(\"id\", T.StringType(), True),\n",
    "    T.StructField(\"date\", T.StringType(), True),\n",
    "    T.StructField(\"flag\", T.StringType(), True),\n",
    "    T.StructField(\"user\", T.StringType(), True),\n",
    "    T.StructField(\"text\", T.StringType(), True),\n",
    "])\n",
    "sentiment140_spark = spark.read.csv('../data/sentiment140.csv', schema=sentiment140Schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f659de7-1450-4304-a9e2-7d886cf6e0a6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- target: string (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- date: string (nullable = true)\n",
      " |-- flag: string (nullable = true)\n",
      " |-- user: string (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['target', 'id', 'date', 'flag', 'user', 'text']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment140_spark.printSchema()\n",
    "sentiment140_spark.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dcdb8892-b7aa-4d8d-a3ee-ca41ee0ab0df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+--------------------+--------+---------------+--------------------+\n",
      "|target|        id|                date|    flag|           user|                text|\n",
      "+------+----------+--------------------+--------+---------------+--------------------+\n",
      "|     0|1467810369|Mon Apr 06 22:19:...|NO_QUERY|_TheSpecialOne_|@switchfoot http:...|\n",
      "|     0|1467810672|Mon Apr 06 22:19:...|NO_QUERY|  scotthamilton|is upset that he ...|\n",
      "|     0|1467810917|Mon Apr 06 22:19:...|NO_QUERY|       mattycus|@Kenichan I dived...|\n",
      "|     0|1467811184|Mon Apr 06 22:19:...|NO_QUERY|        ElleCTF|my whole body fee...|\n",
      "|     0|1467811193|Mon Apr 06 22:19:...|NO_QUERY|         Karoli|@nationwideclass ...|\n",
      "|     0|1467811372|Mon Apr 06 22:20:...|NO_QUERY|       joy_wolf|@Kwesidei not the...|\n",
      "|     0|1467811592|Mon Apr 06 22:20:...|NO_QUERY|        mybirch|         Need a hug |\n",
      "|     0|1467811594|Mon Apr 06 22:20:...|NO_QUERY|           coZZ|@LOLTrish hey  lo...|\n",
      "|     0|1467811795|Mon Apr 06 22:20:...|NO_QUERY|2Hood4Hollywood|@Tatiana_K nope t...|\n",
      "|     0|1467812025|Mon Apr 06 22:20:...|NO_QUERY|        mimismo|@twittera que me ...|\n",
      "+------+----------+--------------------+--------+---------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentiment140_spark.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21cfdc08-f8e5-476f-9c38-78ddb3b9aed0",
   "metadata": {},
   "source": [
    "The columns ```id``` and ```user``` do not hold any such information that the mode can learn. So these columns can be dropped.\n",
    "\n",
    "We will check what other values the ```flag``` column holds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b4a0d7c8-d0dd-4355-9d58-581948c1db8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|    flag|\n",
      "+--------+\n",
      "|NO_QUERY|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentiment140_spark.select('flag').distinct().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f1d55c-6177-413e-b408-b89ad8321cc2",
   "metadata": {},
   "source": [
    "Since there is only one unique entry in this column, our model cannot learn anything from this column. So we can drop this column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fbc409a1-6a86-454c-bd4c-8d9ede978ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment140_spark = sentiment140_spark.drop(*['id', 'user', 'flag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "77da2333-bc03-40ce-9609-409888da5863",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['target', 'date', 'text']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment140_spark.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db022607-e6c0-41e7-9092-296ebeb1e3bf",
   "metadata": {},
   "source": [
    "We will modify the ```date``` field to hold date time values that can be parsed easily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7673d79f-5114-473d-b559-dbe138c43010",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mon Apr 06 22:19:45 PDT 2009'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment140_spark.select('date').first()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af33398a-e63c-4e89-94f3-ec66e262dcfa",
   "metadata": {},
   "source": [
    "Creating UDF to transform the ```date``` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2b4231bb-64c7-4f1e-a45a-f2728d99276b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "162f5092-2a20-4576-82db-5da46f9aa6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import calendar\n",
    "month_mapper = {month: index for index, month in enumerate(calendar.month_abbr) if month}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "546fa6b1-2b4c-4435-ab89-24b0d32cff2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_date(date):\n",
    "  date_split = date.replace('PDT', '').split()[1:]\n",
    "  month = month_mapper[date_split[0]]\n",
    "  day = date_split[1]\n",
    "  time = date_split[2]\n",
    "  year = date_split[3]\n",
    "  date_string = str(month) + ' ' + str(day) + ' ' + str(time) + ' ' + str(year)\n",
    "  datetime_object = datetime.strptime(date_string, '%m %d %H:%M:%S %Y')\n",
    "  return str(datetime_object)  # printed in default format\n",
    "transform_date_udf = F.udf(transform_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b2a73c8f-2956-4b28-87bc-a2c87bf1dcf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment140_spark = sentiment140_spark\\\n",
    "  .withColumn('Date', transform_date_udf(F.col('date'))).select(['target', 'Date', 'text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e64d8634-08d1-4913-9998-577c630fab6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------------+--------------------+\n",
      "|target|               Date|                text|\n",
      "+------+-------------------+--------------------+\n",
      "|     0|2009-04-06 22:19:45|@switchfoot http:...|\n",
      "|     0|2009-04-06 22:19:49|is upset that he ...|\n",
      "|     0|2009-04-06 22:19:53|@Kenichan I dived...|\n",
      "|     0|2009-04-06 22:19:57|my whole body fee...|\n",
      "|     0|2009-04-06 22:19:57|@nationwideclass ...|\n",
      "|     0|2009-04-06 22:20:00|@Kwesidei not the...|\n",
      "|     0|2009-04-06 22:20:03|         Need a hug |\n",
      "|     0|2009-04-06 22:20:03|@LOLTrish hey  lo...|\n",
      "|     0|2009-04-06 22:20:05|@Tatiana_K nope t...|\n",
      "|     0|2009-04-06 22:20:09|@twittera que me ...|\n",
      "+------+-------------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentiment140_spark.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bdf9c9d-7ba7-42e4-9f40-98ca0dd91be6",
   "metadata": {},
   "source": [
    "Now the dataframe has properly formatted date.\n",
    "\n",
    "We will now view how many unique values of ```target``` are there in our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f1c61260-322b-4514-b1ff-d7d9350e6ce5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+\n",
      "|target| Count|\n",
      "+------+------+\n",
      "|     0|800000|\n",
      "|     4|800000|\n",
      "+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentiment140_spark.groupBy('target').agg(F.count('target').alias('Count')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493a15ef-1086-43a3-b237-959a9aac39dd",
   "metadata": {},
   "source": [
    "This DataFrame has equal number of occurences of the 2 categories:\n",
    "\n",
    "0 $\\Rightarrow$ Negative sentiment <br>\n",
    "4 $\\Rightarrow$ Positive sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb9eec2-53ee-4d72-9352-6f87de495565",
   "metadata": {},
   "source": [
    "We will have common labels across dataframes $\\rightarrow 0$ will signify negative sentiment and $1$ will signify positive sentiment\n",
    "\n",
    "We will write a UDF to perform this transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "10ab1c26-7f2f-45f6-b4dc-99221677d784",
   "metadata": {},
   "outputs": [],
   "source": [
    "def common_label_transform(label_value, negative_sentiment, positive_sentiment):\n",
    "  return 0 if label_value == negative_sentiment else 1\n",
    "common_label_transform_udf = F.udf(common_label_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c275fc4a-7abd-4d92-89ed-0e91f8b6cdb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# twitter_data = twitter_data\\\n",
    "#   .withColumn('label', F.lit(common_label_transform_udf(F.col('category'), F.lit(\"-1.0\"), F.lit(\"1.0\"))))\\\n",
    "#   .select(['text', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "da225aa6-5e37-4318-be26-8205b3717ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment140_spark = sentiment140_spark\\\n",
    "  .withColumn('label', F.lit(common_label_transform_udf(F.col('target'), F.lit(\"0\"), F.lit(\"4\"))))\\\n",
    "  .select(['text', 'label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3003aa2a-42ff-4c8c-bef2-df3f73e238bf",
   "metadata": {},
   "source": [
    "Export all the preprocessed spark dataframes into database - here, we are using MongoDb\n",
    "\n",
    "Storing in csv files for now $\\rightarrow$ (create the folder ```data-processed``` if it is not present)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5ebf5389-ada3-4211-8241-ace69049c547",
   "metadata": {},
   "outputs": [],
   "source": [
    "# twitter_data.toPandas().to_csv('../data-processed/Twitter_Data.csv')\n",
    "# sentiment140 = sentiment140_spark.toPandas().to_csv('../data-processed/sentiment140_data.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
