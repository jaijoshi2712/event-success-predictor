{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4017c48d-49d8-45a0-990c-833224419912",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import pyspark.sql.functions as F\n",
    "import pyspark.sql.types as T\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fc756c81-6159-4e4b-ae3c-929b378df747",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark context already exists, continuing with <SparkContext master=local[*] appName=pyspark-shell>\n"
     ]
    }
   ],
   "source": [
    "conf = pyspark.SparkConf()\n",
    "conf.set('spark.ui.proxyBase', '/user/' + os.environ['JUPYTERHUB_USER'] + '/proxy/4041')\n",
    "conf.set('spark.driver.memory','8g')\n",
    "conf.set('spark.ui.showConsoleProgress', False)\n",
    "try:\n",
    "    sc = pyspark.SparkContext(conf=conf)\n",
    "    spark = pyspark.SQLContext.getOrCreate(sc)\n",
    "except:\n",
    "    print('Spark context already exists, continuing with', sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "45b471ad-0e6f-44a9-8e71-a94017fbe138",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sentiment140 = spark.read.csv('../data-processed/sentiment140_data.csv', header=True).select(['text', 'label'])\n",
    "sentiment140 = spark.read.csv('../data/reduced_data.csv', header=True).select(['text', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c9facc66-6177-4c49-931a-eaf6bc81f7b5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|                text|label|\n",
      "+--------------------+-----+\n",
      "|I LOVE @Health4Ua...|    1|\n",
      "|im meeting up wit...|    1|\n",
      "|@DaRealSunisaKim ...|    1|\n",
      "|Being sick can be...|    1|\n",
      "|@LovesBrooklyn2 h...|    1|\n",
      "|@ProductOfFear Yo...|    1|\n",
      "|@r_keith_hill Tha...|    1|\n",
      "|@KeepinUpWKris I ...|    1|\n",
      "|@tommcfly ah, con...|    1|\n",
      "|@e4VoIP I RESPOND...|    1|\n",
      "|crazy day of scho...|    1|\n",
      "|@naughtyhaughty H...|    1|\n",
      "|@nileyjileyluver ...|    1|\n",
      "|@soundwav2010 At ...|    1|\n",
      "|@LutheranLucciol ...|    1|\n",
      "|Just added tweeti...|    1|\n",
      "|@michellardi i re...|    1|\n",
      "|@nicolerichie: yo...|    1|\n",
      "|Catching Up on Em...|    1|\n",
      "|Dancing around th...|    1|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentiment140.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822fafa2-b1b8-41e7-acdd-0e19f269b263",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741a30d7-a039-4a2a-b5ab-0aa275c4f36b",
   "metadata": {},
   "source": [
    "We will follow the following steps to prepare the data for our model\n",
    "1. Lowercase the text\n",
    "2. Remove stopwords from text\n",
    "3. Remove punctuations from text since that is noise and meaningful information cannot be learned from them\n",
    "4. Remove usernames, emojis, urls etc.\n",
    "5. Replace contractions\n",
    "6. Tokenize the text\n",
    "7. Perform stemming and lemmatization on text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b1ce9b-1629-45e6-bb3a-27e089d18ed3",
   "metadata": {},
   "source": [
    "#### Lowercase the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "709559a0-5aec-4235-a010-67784ea9f99b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sentiment140 = sentiment140.withColumn('text', F.lower(F.col('text')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f9218b97-1998-4e25-8460-d83724b81194",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|                text|label|\n",
      "+--------------------+-----+\n",
      "|i love @health4ua...|    1|\n",
      "|im meeting up wit...|    1|\n",
      "|@darealsunisakim ...|    1|\n",
      "|being sick can be...|    1|\n",
      "|@lovesbrooklyn2 h...|    1|\n",
      "|@productoffear yo...|    1|\n",
      "|@r_keith_hill tha...|    1|\n",
      "|@keepinupwkris i ...|    1|\n",
      "|@tommcfly ah, con...|    1|\n",
      "|@e4voip i respond...|    1|\n",
      "+--------------------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentiment140.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0915c9-c5d7-48a2-a3da-5ef32a06aa3f",
   "metadata": {},
   "source": [
    "#### Remove stopwords from text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a0d945a9-e199-4730-85aa-7dc8e20ea65d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "45383729-5b95-43a5-b352-5e669e523782",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8b072b17-de36-4045-a5f7-7de19d56581c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.words('english')[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f8c36502-cc91-4f20-996c-6c9382c85af7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def removeStopwords(text):\n",
    "  return \" \".join([word for word in text.split() if word not in stopwords.words('english')])\n",
    "\n",
    "removeStopwordsUDF = F.udf(removeStopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4e16a281-41fe-4038-9907-7957e13291d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sentiment140 = sentiment140.withColumn('text', removeStopwordsUDF(F.col('text')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b26473bd-bbe4-4708-a667-7efe27edb25f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|                text|label|\n",
      "+--------------------+-----+\n",
      "|love @health4uand...|    1|\n",
      "|im meeting one be...|    1|\n",
      "|@darealsunisakim ...|    1|\n",
      "|sick really cheap...|    1|\n",
      "|@lovesbrooklyn2 e...|    1|\n",
      "|@productoffear te...|    1|\n",
      "|@r_keith_hill tha...|    1|\n",
      "|@keepinupwkris je...|    1|\n",
      "|@tommcfly ah, con...|    1|\n",
      "|@e4voip responded...|    1|\n",
      "+--------------------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentiment140.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8924a0-c499-4cb4-993f-4f6458be8e6c",
   "metadata": {},
   "source": [
    "#### Remove punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c0bc753e-2eae-436d-b848-c5ba0230c0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ed4ec634-cbe0-4383-abec-7d9d4e188923",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4ec52a0d-8bbf-4499-9417-05735170dcb4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def remove_punctuations(text):\n",
    "    # Make a translation table that maps all punctuation characters to None\n",
    "    translator = str.maketrans(\"\", \"\", string.punctuation)\n",
    "\n",
    "    # Apply the translation table to the input string\n",
    "    return text.translate(translator)\n",
    "\n",
    "removePunctuationsUDF = F.udf(remove_punctuations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9e696b29-67c2-4ef8-95da-a60edc96ade6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sentiment140 = sentiment140.withColumn('text', removePunctuationsUDF(F.col('text')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "05c6f3a3-9364-441d-bdf7-35d29d700430",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|                text|label|\n",
      "+--------------------+-----+\n",
      "|love health4uandp...|    1|\n",
      "|im meeting one be...|    1|\n",
      "|darealsunisakim t...|    1|\n",
      "|sick really cheap...|    1|\n",
      "|lovesbrooklyn2 ef...|    1|\n",
      "|productoffear tel...|    1|\n",
      "|rkeithhill thans ...|    1|\n",
      "|keepinupwkris jea...|    1|\n",
      "|tommcfly ah congr...|    1|\n",
      "|e4voip responded ...|    1|\n",
      "+--------------------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentiment140.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fda7b0c-5970-4047-8b38-b60ec8654293",
   "metadata": {},
   "source": [
    "#### Remove emails, emojis, urls etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a47041df-af41-4b28-b046-962614db04f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import emoji\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "55fef8ee-53d4-440b-bc3a-921f1a717a2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "url_regex = '((www\\.[^\\s]+)|(https?://[^\\s]+))'\n",
    "username_regex = '@[^\\s]+'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6125183f-2ad8-49d1-82fc-55fbf81d661b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def remove_urls(text):\n",
    "  return re.sub(url_regex, '', text)\n",
    "\n",
    "def remove_usernames(text):\n",
    "  return re.sub(username_regex, '', text)\n",
    "\n",
    "def remove_emojis(text):\n",
    "  return emoji.demojize(text)\n",
    "\n",
    "remove_urlsUDF = F.udf(remove_urls)\n",
    "remove_usernamesUDF = F.udf(remove_usernames)\n",
    "remove_emojisUDF = F.udf(remove_emojis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "749cca71-0c7e-4d04-aaa0-a7b4a1880c30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sentiment140 = sentiment140.withColumn('text', remove_urlsUDF(F.col('text')))\n",
    "sentiment140 = sentiment140.withColumn('text', remove_usernamesUDF(F.col('text')))\n",
    "sentiment140 = sentiment140.withColumn('text', remove_emojisUDF(F.col('text')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d7431c-0dec-4b82-a23f-d57f3a55af8d",
   "metadata": {},
   "source": [
    "#### Tokenizing, stemming, and lemmatizing the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1f759df8-699d-47ea-81b0-16aab26f774c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "78bce0f1-68b1-4b66-b28a-85bebfe2d062",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tokenize_stem_lemmatize(text):\n",
    "    tokenizer = RegexpTokenizer('\\w+')\n",
    "    tokenized_words = tokenizer.tokenize(text)\n",
    "    \n",
    "    # Stemming logic\n",
    "    stemmer = PorterStemmer()\n",
    "    stemmed_words = [stemmer.stem(word) for word in tokenized_words]\n",
    "    \n",
    "    # Lemmatizing logic\n",
    "    lemmatizer = nltk.WordNetLemmatizer()\n",
    "    lemmatized_words = [lemmatizer.lemmatize(word, pos = 'a') for word in stemmed_words]\n",
    "    \n",
    "    return ' '.join(lemmatized_words)\n",
    "\n",
    "tokenize_stem_lemmatizeUDF = F.udf(tokenize_stem_lemmatize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "cf32e8c2-650e-4d79-b0b5-bbeaff330d75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sentiment140 = sentiment140.withColumn('text', tokenize_stem_lemmatizeUDF(F.col('text')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f66ec521-11c2-4348-823a-90bfdd479926",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|                text|label|\n",
      "+--------------------+-----+\n",
      "|love health4uandp...|    1|\n",
      "|im meet one besti...|    1|\n",
      "|darealsunisakim t...|    1|\n",
      "|sick realli cheap...|    1|\n",
      "|lovesbrooklyn2 ef...|    1|\n",
      "|productoffear tel...|    1|\n",
      "|rkeithhil than re...|    1|\n",
      "|keepinupwkri jeal...|    1|\n",
      "|tommcfli ah congr...|    1|\n",
      "|e4voip respond st...|    1|\n",
      "+--------------------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentiment140.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c127020-75a1-4878-9a11-ddccbace8718",
   "metadata": {},
   "source": [
    "#### Removing rows with null labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "35c632ae-cad4-4f05-8529-f6623f9d08f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sentiment140 = sentiment140.filter(~F.col('label').isNull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cf5c8f23-91a3-4df9-9996-d2d23bf3dd85",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sentiment140.toPandas().to_csv('../data-processed/sentiment140_model_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ebd19bd-a5f0-4743-bcb0-571c9d340fbe",
   "metadata": {},
   "source": [
    "Storing the dataframe in a parquet file. This will be used to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "61262880-7b53-4117-bf2f-842f6bf8443a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory already exists at path...\n",
      "Deleting the directory\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "try:\n",
    "    sentiment140.write.parquet(\"../data-processed/sentiment140_model_data.parquet\")\n",
    "except:\n",
    "    print('Directory already exists at path...\\nDeleting the directory')\n",
    "    shutil.rmtree('../data-processed/sentiment140_model_data.parquet')\n",
    "    sentiment140.write.parquet(\"../data-processed/sentiment140_model_data.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
