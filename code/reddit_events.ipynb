{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56c409e5-1e43-45b2-b184-2e7dab03a7d1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: praw in ./.local/lib/python3.10/site-packages (7.7.1)\n",
      "Requirement already satisfied: prawcore<3,>=2.1 in ./.local/lib/python3.10/site-packages (from praw) (2.4.0)\n",
      "Requirement already satisfied: update-checker>=0.18 in ./.local/lib/python3.10/site-packages (from praw) (0.18.0)\n",
      "Requirement already satisfied: websocket-client>=0.54.0 in ./.local/lib/python3.10/site-packages (from praw) (1.7.0)\n",
      "Requirement already satisfied: requests<3.0,>=2.6.0 in ./.local/lib/python3.10/site-packages (from prawcore<3,>=2.1->praw) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.local/lib/python3.10/site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/bigdata/lib/python3.10/site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.local/lib/python3.10/site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/bigdata/lib/python3.10/site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (2023.11.17)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install praw\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0beb17b-aaae-4741-b7f5-7f37574858d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import praw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d00f6fd-04f4-47e2-a335-c6c150b1955a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "reddit = praw.Reddit(\n",
    "    client_id=\"\",\n",
    "    client_secret=\"\",\n",
    "    password=\"\",\n",
    "    user_agent=\"\",\n",
    "    username=\"\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "760031d0-d42e-4118-9cf0-a24c5aa494db",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/12/14 16:47:46 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "/opt/conda/envs/bigdata/lib/python3.10/site-packages/pyspark/sql/pandas/conversion.py:485: FutureWarning: is_datetime64tz_dtype is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.DatetimeTZDtype)` instead.\n",
      "  if should_localize and is_datetime64tz_dtype(s.dtype) and s.dt.tz is not None:\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-------------------+------------+--------------------+\n",
      "|               title|                 url|            created|num_comments|            comments|\n",
      "+--------------------+--------------------+-------------------+------------+--------------------+\n",
      "|Rockefeller Cente...|https://www.reddi...|2023-11-30 05:50:02|         634|[I swear I feel l...|\n",
      "|NYC Drag Story Ho...|https://www.nbcne...|2022-12-19 14:52:13|         500|[why is there nev...|\n",
      "|Drama at a drag q...|https://v.redd.it...|2022-12-12 07:28:34|         474|[So apparently th...|\n",
      "|Eric Adams attend...|https://www.polit...|2023-11-17 13:41:16|          87|[I just do that o...|\n",
      "|NYC Mayor Adams i...|https://www.nydai...|2023-05-12 18:19:26|         144|[CUNY Law invited...|\n",
      "|NYC's Newest Park...|https://i.redd.it...|2021-05-21 17:03:37|         194|[I had no idea th...|\n",
      "|Republican Jewish...|https://www.haare...|2022-12-27 17:07:57|         103|[This guy is lite...|\n",
      "|Trump Attends UFC...|https://www.theda...|2019-11-03 12:41:48|         332|[[deleted], His e...|\n",
      "|Ahead of potentia...|https://www.polit...|2023-02-19 17:28:21|         122|[How can any law ...|\n",
      "|'Change in percep...|https://www.nbcne...|2021-12-18 16:10:25|         206|[Iâ€™m not going to...|\n",
      "+--------------------+--------------------+-------------------+------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import praw\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder.appName('RedditData').getOrCreate()\n",
    "\n",
    "subreddit_name = 'nyc'  # Change this to your target subreddit\n",
    "search_query = 'event'  # Modify this based on how events are typically posted\n",
    "six_months_ago = datetime.utcnow() - timedelta(days=6*30)  # Approximation of 6 months\n",
    "\n",
    "# Create a list to store event data\n",
    "events = []\n",
    "\n",
    "# Search the subreddit for posts containing 'event' in the title\n",
    "for submission in reddit.subreddit(subreddit_name).search(search_query, limit=10):  # Adjust the limit as needed\n",
    "    # if datetime.utcfromtimestamp(submission.created_utc) > six_months_ago:\n",
    "        submission.comments.replace_more(limit=None)  # Load all comments\n",
    "        comments = [comment.body for comment in submission.comments.list()]\n",
    "        event_info = (\n",
    "            submission.title,\n",
    "            submission.url,\n",
    "            datetime.utcfromtimestamp(submission.created_utc).strftime('%Y-%m-%d %H:%M:%S'),\n",
    "            len(comments),\n",
    "            comments\n",
    "        )\n",
    "        events.append(event_info)\n",
    "\n",
    "# Convert to Pandas DataFrame\n",
    "columns = ['title', 'url', 'created', 'num_comments', 'comments']\n",
    "df = pd.DataFrame(events, columns=columns)\n",
    "\n",
    "# Convert Pandas DataFrame to Spark DataFrame\n",
    "spark_df = spark.createDataFrame(df)\n",
    "spark_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bfdd7be-3d21-48a1-9f89-d94324c43391",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:bigdata]",
   "language": "python",
   "name": "conda-env-bigdata-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
